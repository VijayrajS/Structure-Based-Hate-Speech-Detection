{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "N_Gram_oversampled.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI5J4dpLT2bG"
      },
      "source": [
        "# N Gram model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjJiyroeT2bS"
      },
      "source": [
        "### Importing prerequisite libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzKFsqNLT2bV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f5699dc-bc55-4caa-ed01-6606968cad9f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter\n",
        "\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGeX-Rs_T2bq"
      },
      "source": [
        "### Loading datasets and dropping nulls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0REa9i2BT2bs"
      },
      "source": [
        "data = pd.read_csv('dataset.csv',sep=',',names=['Msg','Tag'])\n",
        "data1 = pd.read_csv('dataset_POS.csv',sep=',',names=['Msg','Tag'])\n",
        "data2 = pd.read_csv('dataset_stemmed.csv',sep=',',names=['Msg','Tag'])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UTtOLhOT2cF"
      },
      "source": [
        "data.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB_z_glxT2cc"
      },
      "source": [
        "data1.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwUWMAPmT2cv"
      },
      "source": [
        "data2.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mytoY4npT2c8"
      },
      "source": [
        "data_x=data[\"Msg\"]\n",
        "data_y=data[\"Tag\"]\n",
        "\n",
        "# x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=0.2, random_state=4)\n",
        "\n",
        "data_X=data1[\"Msg\"]\n",
        "data_Y=data1[\"Tag\"]\n",
        "\n",
        "# x1_train, x1_test, y1_train, y1_test = train_test_split(data1_x, data1_y, test_size=0.2, random_state=4)\n",
        "\n",
        "data2_x=data2[\"Msg\"]\n",
        "data2_y=data2[\"Tag\"]\n",
        "\n",
        "# x2_train, x2_test, y2_train, y2_test = train_test_split(data2_x, data2_y, test_size=0.2, random_state=4)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLJvyNImCis7"
      },
      "source": [
        "en_stopwords = set(stopwords.words(\"english\"))\n",
        "\n",
        "def tokenize(text):\n",
        "  return text.split()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP3po75bRFdm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcb38504-3539-42de-c1ad-3cceb6d2ab8d"
      },
      "source": [
        "types = [(1,1),(1,2),(1,3),(1,4)]\n",
        "names = ['unigram','bigram','trigram','four gram']\n",
        "ans = {}\n",
        "ans['model'] = []\n",
        "ans['F1-score'] = []\n",
        "ans['Recall'] = []\n",
        "ans['Accuracy'] = []\n",
        "ans['Precision'] = []\n",
        "\n",
        "for i in range(len(types)):\n",
        "    cv = CountVectorizer(\n",
        "        analyzer = 'word',\n",
        "        lowercase = True,\n",
        "        tokenizer = tokenize,\n",
        "        ngram_range=types[i],\n",
        "        stop_words = en_stopwords)\n",
        "\n",
        "    # vectorizer.fit(x1_train)\n",
        "    # train_set = vectorizer.transform(x1_train)\n",
        "    # test_set = vectorizer.transform(x1_test)\n",
        "    string = names[i]+' '+'using LR'\n",
        "\n",
        "    x_cv=cv.fit_transform(data_X.values.astype('U'))\n",
        "\n",
        "    print(Counter(data_Y))\n",
        "\n",
        "    oversample = SMOTE()\n",
        "    x, y = oversample.fit_sample(x_cv, data_Y)\n",
        "\n",
        "    print(Counter(y))\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)\n",
        "\n",
        "    #Testing results with LR\n",
        "    lr = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')  \n",
        "    lr.fit(x_train, y_train)\n",
        "    prediction = lr.predict(x_test)\n",
        "    \n",
        "    f1 = f1_score(y_test, prediction, average='weighted')\n",
        "    acc = accuracy_score(y_test, prediction)\n",
        "    rec = recall_score(y_test, prediction, average = 'macro')\n",
        "    pre = precision_score(y_test, prediction, average='macro')\n",
        "    \n",
        "    ans['model'].append(string)\n",
        "    ans['F1-score'].append(f1)\n",
        "    ans['Recall'].append(rec)\n",
        "    ans['Accuracy'].append(acc)\n",
        "    ans['Precision'].append(pre)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 9507, 1: 1437})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Counter({1: 9507, 0: 9507})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 9507, 1: 1437})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Counter({1: 9507, 0: 9507})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 9507, 1: 1437})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Counter({1: 9507, 0: 9507})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 9507, 1: 1437})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Counter({1: 9507, 0: 9507})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeguIrg5EQJT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "bf0e2e1b-352b-4387-8068-decde0e076bd"
      },
      "source": [
        "import operator\n",
        "final = pd.DataFrame(ans)\n",
        "final"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>F1-score</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>unigram using LR</td>\n",
              "      <td>0.821951</td>\n",
              "      <td>0.822080</td>\n",
              "      <td>0.823034</td>\n",
              "      <td>0.830107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bigram using LR</td>\n",
              "      <td>0.827239</td>\n",
              "      <td>0.827209</td>\n",
              "      <td>0.828031</td>\n",
              "      <td>0.833315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>trigram using LR</td>\n",
              "      <td>0.828706</td>\n",
              "      <td>0.828609</td>\n",
              "      <td>0.829345</td>\n",
              "      <td>0.833584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>four gram using LR</td>\n",
              "      <td>0.826433</td>\n",
              "      <td>0.826306</td>\n",
              "      <td>0.826979</td>\n",
              "      <td>0.830457</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                model  F1-score    Recall  Accuracy  Precision\n",
              "0    unigram using LR  0.821951  0.822080  0.823034   0.830107\n",
              "1     bigram using LR  0.827239  0.827209  0.828031   0.833315\n",
              "2    trigram using LR  0.828706  0.828609  0.829345   0.833584\n",
              "3  four gram using LR  0.826433  0.826306  0.826979   0.830457"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}